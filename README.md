# Microsoft-Sentense Completion-ANLP
This report focuses on building and evaluating different Natural Language models like n-gram models and word embedding models to take the Microsoft Sentence Completion Challenge (SCC) (Geoffrey Zweig, 2011). Also, the developed methods are compared to each other based on the accuracy and the models are introspected by varying different hyper-parameters and are explained in this report. The results are compared with the unigram and bigram baselines. The MSR Sentence Completion Challenge consists of 1040 sentences from five Sherlock Holmes Novels are given along with four imposter sentences for each of these sentences. These imposter sentences are made by varying a single word in each sentence. The statistical occurrences of imposter words are similar to the original word which has been replaced. The challenge here is to correctly predict the original word from the five options consisting of four imposter words and the correct word. The data set is made from the Project Gutenberg data with most of the data selected from 19th-century novels (Geoffrey Zweig, 2011). By building and analysing the performance of various models on these test sentences, we may more easily study the theory behind those implementations and identify nuances in the dataset. By documenting the changes in the performance of the models while attempting to maximise each one's score on the SCC, we can explore the effects of different features and hyper-parameter settings during the development process, and hopefully gain insights into how the different models process natural language.
